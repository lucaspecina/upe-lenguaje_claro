{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lenguaje Claro - UPE\n",
    "Lucas Pecina\n",
    "\n",
    "09/01/21\n",
    "\n",
    "---\n",
    "### Objetivo\n",
    "Comparar distintos textos (legales, judiciales, etc) para ver la complejidad que tiene ese texto en cuanto a palabras dificiles (poco frecuentes en el lenguaje cotidiano).\n",
    "\n",
    "### Resumen\n",
    "El lenguaje legal/judicial suele ser complicado de entender para la gente que no se dedica a temas relacionados debido a la complejidad de las palabras utilizadas y de su gramatica. El analisis de complejidad gramatical de los textos requiere la utilizacion de tecnicas muy sofisticadas y que no dan buenos resultados, por lo tanto, descartamos este tipo de estudio por el momento.\n",
    "\n",
    "Comenzamos solo analizando las **palabras** de los textos y creamos un **indice de complejidad** que mide la cantidad y frecuencia de palabras \"complejas\", que son de poca frecuencia en el lenguaje cotidiano. \n",
    "\n",
    "No contaran para el calculo aquellas palabras que por su naturaleza tecnica juridica requiera de su uso obligatorio. Para dicha tarea, se elaborara a mano una lista de las palabras en cuestion.\n",
    "\n",
    "### Fuentes de datos\n",
    "- Textos a analizar: seran cargados como archivos de texto\n",
    " - Codigo Procesal Civil y Comercial actual http://biblioteca.asesoria.gba.gov.ar/redirect.php?id=2121 esta en un archivo CPCC\n",
    " - Codigo Procesal Penal actual http://servicios.infoleg.gob.ar/infolegInternet/anexos/0-4999/383/texact.htm \n",
    "- Bolsa de palabras de frecuencia del lenguaje español http://corpus.rae.es/lfrecuencias.html. Usando las 300mil palabras mas frecuentes del español: en datos/\n",
    "\n",
    "### Pasos\n",
    "1. Corpus de palabras frecuentes\n",
    " - Armar dataframe con frecuencias\n",
    " - Calcular complejidad de palabras\n",
    "2. Cargar textos y preprocesarlo\n",
    " - Tokenizar las palabras\n",
    " - Limpiar errores\n",
    " - Remover stopwords\n",
    "\n",
    "\n",
    "---\n",
    "### Indice de complejidad del lenguaje\n",
    "$$Complejidad_t = \\frac{1}{P}\\sum_p^P{Complejidad_p}$$\n",
    "\n",
    "- t = texto a analizar\n",
    "- p = lista de palabras en el texto t (pueden estar repetidas)\n",
    "- P = cantidad de palabras en el texto t (todas)\n",
    "\n",
    "$$Complejidad_p = f(FrecuenciaBolsa_p)$$\n",
    "> **DETERMINAR EL INDICE DE COMPLEJIDAD DE LAS PALABRAS**. \n",
    "Ver la distribucion de frecuencias (despues de remover stopwords). Ver si hacerlo por frecuencia de palabras o ranking.\n",
    "Puede ser el ranking o el inverso de las frecuencias.\n",
    "\n",
    "$$Complejidad_p = \\frac{1}{FrecuenciaBolsa_p}$$\n",
    "\n",
    "o\n",
    "\n",
    "$$Complejidad_p = RankingBolsa_p$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus de palabras frecuentes del español\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orden</th>\n",
       "      <th>Palabra</th>\n",
       "      <th>Frecuencia</th>\n",
       "      <th>Frecuencia_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>de</td>\n",
       "      <td>9999518</td>\n",
       "      <td>65545.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>la</td>\n",
       "      <td>6277560</td>\n",
       "      <td>41148.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>que</td>\n",
       "      <td>4681839</td>\n",
       "      <td>30688.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>el</td>\n",
       "      <td>4569652</td>\n",
       "      <td>29953.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>en</td>\n",
       "      <td>4234281</td>\n",
       "      <td>27755.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423729</th>\n",
       "      <td>423730</td>\n",
       "      <td>zyscovich</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423730</th>\n",
       "      <td>423731</td>\n",
       "      <td>zyx</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423731</th>\n",
       "      <td>423732</td>\n",
       "      <td>zzz</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423732</th>\n",
       "      <td>423733</td>\n",
       "      <td>zzzzzzzzzzz</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423733</th>\n",
       "      <td>423734</td>\n",
       "      <td>zzzzzzzzzzzzzzz</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>423733 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Orden          Palabra  Frecuencia  Frecuencia_norm\n",
       "0            1               de     9999518         65545.55\n",
       "1            2               la     6277560         41148.59\n",
       "2            3              que     4681839         30688.85\n",
       "3            4               el     4569652         29953.48\n",
       "4            5               en     4234281         27755.16\n",
       "...        ...              ...         ...              ...\n",
       "423729  423730        zyscovich           2             0.01\n",
       "423730  423731              zyx           2             0.01\n",
       "423731  423732              zzz           2             0.01\n",
       "423732  423733      zzzzzzzzzzz           2             0.01\n",
       "423733  423734  zzzzzzzzzzzzzzz           2             0.01\n",
       "\n",
       "[423733 rows x 4 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cargo datos\n",
    "corpus = pd.read_excel('/Users/lucaspecina/Desktop/Data/Planificacion Estrategica/lenguaje-claro/upe-lenguaje_claro/datos/CREA_total.xlsx')\n",
    "corpus = corpus.dropna()\n",
    "corpus['Palabra'] = corpus.Palabra.astype('str').str.strip()\n",
    "corpus = corpus[corpus.Frecuencia_norm>0.00]\n",
    "\n",
    "# reemplazo caracteres mal cargados\n",
    "reemplazar = {'·':'á','È':'é','Ò':'ñ','˙':'ú','¸':'ü','Ì':'í','Û':'ó'}\n",
    "\n",
    "for k,v in reemplazar.items():\n",
    "    corpus['Palabra'] = corpus.Palabra.str.replace(k,v)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "995706.050000001"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.Frecuencia_norm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orden</th>\n",
       "      <th>Palabra</th>\n",
       "      <th>Frecuencia</th>\n",
       "      <th>Frecuencia_norm</th>\n",
       "      <th>complejidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>de</td>\n",
       "      <td>9999518</td>\n",
       "      <td>65545.55</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>la</td>\n",
       "      <td>6277560</td>\n",
       "      <td>41148.59</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>que</td>\n",
       "      <td>4681839</td>\n",
       "      <td>30688.85</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>el</td>\n",
       "      <td>4569652</td>\n",
       "      <td>29953.48</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>en</td>\n",
       "      <td>4234281</td>\n",
       "      <td>27755.16</td>\n",
       "      <td>0.000036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423729</th>\n",
       "      <td>423730</td>\n",
       "      <td>zyscovich</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423730</th>\n",
       "      <td>423731</td>\n",
       "      <td>zyx</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423731</th>\n",
       "      <td>423732</td>\n",
       "      <td>zzz</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423732</th>\n",
       "      <td>423733</td>\n",
       "      <td>zzzzzzzzzzz</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423733</th>\n",
       "      <td>423734</td>\n",
       "      <td>zzzzzzzzzzzzzzz</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>423733 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Orden          Palabra  Frecuencia  Frecuencia_norm  complejidad\n",
       "0            1               de     9999518         65545.55     0.000015\n",
       "1            2               la     6277560         41148.59     0.000024\n",
       "2            3              que     4681839         30688.85     0.000033\n",
       "3            4               el     4569652         29953.48     0.000033\n",
       "4            5               en     4234281         27755.16     0.000036\n",
       "...        ...              ...         ...              ...          ...\n",
       "423729  423730        zyscovich           2             0.01   100.000000\n",
       "423730  423731              zyx           2             0.01   100.000000\n",
       "423731  423732              zzz           2             0.01   100.000000\n",
       "423732  423733      zzzzzzzzzzz           2             0.01   100.000000\n",
       "423733  423734  zzzzzzzzzzzzzzz           2             0.01   100.000000\n",
       "\n",
       "[423733 rows x 5 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculo complejidad\n",
    "corpus['complejidad'] = 1/corpus.Frecuencia_norm\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procesamiento de textos a analizar\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion para el preprocesamiento de los textos a cargar\n",
    "\n",
    "def limpieza_textos(raw,corpus):\n",
    "    tokens = nltk.word_tokenize(raw)\n",
    "    tokens = [t.lower() for t in tokens if t.isalpha()]\n",
    "    print(f'El texto original tiene {len(tokens)} palabras.')\n",
    "    print(f'De esas, hay {len(np.unique(np.array(tokens)))} unicas')\n",
    "    \n",
    "    # hay muchos que finalizan en \"are\", 'ere'. Mencionare, juzgare, interpusiere, etc.\n",
    "    # a esos los saco\n",
    "    tokens = [t for t in tokens if ('are' not in t) & ('ere' not in t)]\n",
    "    print(f'Despues de sacarle las palabras que terminan en ARE o ERE, quedan {len(tokens)} palabras.')\n",
    "    print(f'Ahora hay {len(np.unique(np.array(tokens)))} unicas')\n",
    "    \n",
    "    # veo las palabras del texto que no estan en el corpus y las agrego al corpus para que cuenten\n",
    "    no_estan = [t for t in np.unique(np.array(tokens)) if t not in corpus.Palabra.values]\n",
    "    print(f'Hay {len(no_estan)} parabras unicas que no aparecen en el corpus. Las agrego con 100 de complejidad')\n",
    "    \n",
    "    # ahora quedaron solo las que son muy raras o las que estan sin tildes por los titulos\n",
    "    '''Ahora hay que agregar todas estas palabras al df de corpus y agregarle\n",
    "    el valor maximo = 100 '''\n",
    "\n",
    "    no_estan_df = pd.DataFrame({'Palabra':no_estan, 'complejidad':[100.0]*len(no_estan)})\n",
    "    print('no estan df')\n",
    "    print(no_estan_df)\n",
    "    # concat\n",
    "    corpus_ag = pd.concat([corpus[['Palabra','complejidad']],no_estan_df]).reset_index()\n",
    "    \n",
    "    return(tokens,corpus_ag)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion para calcular frecuencias de palabras en texto y calculo el indice_complejidad\n",
    "\n",
    "def crear_indice_complejidad(tokens,corpus,nombre_texto,comunes_sacar):\n",
    "    '''1 crear df de palabras de nombre_texto y las frecuencias\n",
    "       2 joinear y calcular'''\n",
    "\n",
    "    tokens_freq = pd.DataFrame.from_dict(nltk.FreqDist(tokens), orient='index').reset_index()\n",
    "    tokens_freq.columns = ['Palabra','freq']\n",
    "    #tokens_freq['freq_relativa'] = tokens_freq.freq/tokens_freq.freq.sum()\n",
    "\n",
    "    print('tokens_freq')\n",
    "    print(tokens_freq)\n",
    "    \n",
    "    # joinear\n",
    "    tokens_complejidad = corpus.iloc[comunes_sacar:,:].merge(tokens_freq, left_on='Palabra',right_on='Palabra').reset_index(drop=True)\n",
    "    \n",
    "    # calculo indice_complejidad\n",
    "    tokens_complejidad['indice_complejidad'] = (tokens_complejidad.complejidad * tokens_complejidad.freq)/tokens_complejidad.freq.sum()\n",
    "    print(f'la cantidad de palabras que coincidieron en el corpus es de {len(tokens_complejidad)}')\n",
    "    \n",
    "    indice_complejidad = round(sum(tokens_complejidad.indice_complejidad),5)\n",
    "    print(f'INDICE DE COMPLEJIDAD DE {nombre_texto}: {indice_complejidad}')\n",
    "    \n",
    "    return(tokens_complejidad, indice_complejidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion para el preprocesamiento de los textos a cargar\n",
    "\n",
    "def limpieza_textos_simple(raw, sacar_ere_ese=False):\n",
    "    '''Considera como errores/cosas extremas a las palabras que estan\n",
    "    en el texto pero no en el corpus'''\n",
    "    tokens = nltk.word_tokenize(raw)\n",
    "    tokens = [t.lower() for t in tokens if t.isalpha()]\n",
    "    \n",
    "    if sacar_ere_ese:\n",
    "        # saco a los que finalizan en \"are\", 'ere'. Mencionare, juzgare, interpusiere, etc.\n",
    "        tokens = [t for t in tokens if ('are' not in t) & ('ere' not in t)]\n",
    "        print('Luego de sacar las que tienen ARE o ERE (como conociere)')\n",
    "    \n",
    "    print(f'El texto original tiene {len(tokens)} palabras.')\n",
    "    print(f'De esas, hay {len(np.unique(np.array(tokens)))} unicas')\n",
    "\n",
    "    return(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "comunes_sacar = 0\n",
    "sacar_ere_ese = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPCC\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El texto original tiene 62785 palabras.\n",
      "De esas, hay 5627 unicas\n",
      "tokens_freq\n",
      "            Palabra  freq\n",
      "0             libro    23\n",
      "1                 i    32\n",
      "2     disposiciones    45\n",
      "3         generales    16\n",
      "4            título    70\n",
      "...             ...   ...\n",
      "5622       cúmplase     1\n",
      "5623    comuníquese     1\n",
      "5624     publíquese     1\n",
      "5625           dese     1\n",
      "5626      archívese     1\n",
      "\n",
      "[5627 rows x 2 columns]\n",
      "la cantidad de palabras que coincidieron en el corpus es de 5359\n",
      "INDICE DE COMPLEJIDAD DE CPCC actual: 0.81736\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orden</th>\n",
       "      <th>Palabra</th>\n",
       "      <th>Frecuencia</th>\n",
       "      <th>Frecuencia_norm</th>\n",
       "      <th>complejidad</th>\n",
       "      <th>freq</th>\n",
       "      <th>indice_complejidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5210</th>\n",
       "      <td>258917</td>\n",
       "      <td>correspondiere</td>\n",
       "      <td>4</td>\n",
       "      <td>0.02</td>\n",
       "      <td>50.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.021669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5303</th>\n",
       "      <td>350809</td>\n",
       "      <td>compareciere</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.020866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5257</th>\n",
       "      <td>297261</td>\n",
       "      <td>devolutivo</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.020866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5202</th>\n",
       "      <td>253597</td>\n",
       "      <td>apelable</td>\n",
       "      <td>4</td>\n",
       "      <td>0.02</td>\n",
       "      <td>50.0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.018459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5232</th>\n",
       "      <td>267522</td>\n",
       "      <td>irrecurrible</td>\n",
       "      <td>4</td>\n",
       "      <td>0.02</td>\n",
       "      <td>50.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.010433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5273</th>\n",
       "      <td>310387</td>\n",
       "      <td>litispendencia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.009631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5294</th>\n",
       "      <td>332839</td>\n",
       "      <td>admitiere</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.009631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5203</th>\n",
       "      <td>253598</td>\n",
       "      <td>apelante</td>\n",
       "      <td>4</td>\n",
       "      <td>0.02</td>\n",
       "      <td>50.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.008026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5336</th>\n",
       "      <td>392124</td>\n",
       "      <td>notificador</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5259</th>\n",
       "      <td>297747</td>\n",
       "      <td>dispusiere</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Orden         Palabra  Frecuencia  Frecuencia_norm  complejidad  freq  \\\n",
       "5210  258917  correspondiere           4             0.02         50.0    27   \n",
       "5303  350809    compareciere           2             0.01        100.0    13   \n",
       "5257  297261      devolutivo           3             0.01        100.0    13   \n",
       "5202  253597        apelable           4             0.02         50.0    23   \n",
       "5232  267522    irrecurrible           4             0.02         50.0    13   \n",
       "5273  310387  litispendencia           3             0.01        100.0     6   \n",
       "5294  332839       admitiere           2             0.01        100.0     6   \n",
       "5203  253598        apelante           4             0.02         50.0    10   \n",
       "5336  392124     notificador           2             0.01        100.0     5   \n",
       "5259  297747      dispusiere           3             0.01        100.0     5   \n",
       "\n",
       "      indice_complejidad  \n",
       "5210            0.021669  \n",
       "5303            0.020866  \n",
       "5257            0.020866  \n",
       "5202            0.018459  \n",
       "5232            0.010433  \n",
       "5273            0.009631  \n",
       "5294            0.009631  \n",
       "5203            0.008026  \n",
       "5336            0.008026  \n",
       "5259            0.008026  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpcc_f = open('/Users/lucaspecina/Desktop/Data/Planificacion Estrategica/lenguaje-claro/upe-lenguaje_claro/datos/CPCC.txt')\n",
    "cpcc_raw = cpcc_f.read()\n",
    "cpcc_tokens = limpieza_textos_simple(cpcc_raw, sacar_ere_ese)\n",
    "cpcc_tokens, cpcc_indice = crear_indice_complejidad(cpcc_tokens,corpus,'CPCC actual',comunes_sacar)\n",
    "cpcc_tokens.sort_values('indice_complejidad',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPP\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El texto original tiene 44432 palabras.\n",
      "De esas, hay 4445 unicas\n",
      "tokens_freq\n",
      "           Palabra  freq\n",
      "0           codigo    11\n",
      "1         procesal    29\n",
      "2            penal   101\n",
      "3              ley   163\n",
      "4              ver     2\n",
      "...            ...   ...\n",
      "4440  permanecerán     1\n",
      "4441       entrará     1\n",
      "4442     efectuada     1\n",
      "4443       reforma     1\n",
      "4444       órganos     1\n",
      "\n",
      "[4445 rows x 2 columns]\n",
      "la cantidad de palabras que coincidieron en el corpus es de 4357\n",
      "INDICE DE COMPLEJIDAD DE CPP actual: 0.47422\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orden</th>\n",
       "      <th>Palabra</th>\n",
       "      <th>Frecuencia</th>\n",
       "      <th>Frecuencia_norm</th>\n",
       "      <th>complejidad</th>\n",
       "      <th>freq</th>\n",
       "      <th>indice_complejidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4340</th>\n",
       "      <td>381324</td>\n",
       "      <td>labrará</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.015797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4329</th>\n",
       "      <td>326089</td>\n",
       "      <td>supiere</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.015797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4285</th>\n",
       "      <td>253597</td>\n",
       "      <td>apelable</td>\n",
       "      <td>4</td>\n",
       "      <td>0.02</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.012412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336</th>\n",
       "      <td>350809</td>\n",
       "      <td>compareciere</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.009027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4303</th>\n",
       "      <td>267522</td>\n",
       "      <td>irrecurrible</td>\n",
       "      <td>4</td>\n",
       "      <td>0.02</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.007899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4292</th>\n",
       "      <td>258917</td>\n",
       "      <td>correspondiere</td>\n",
       "      <td>4</td>\n",
       "      <td>0.02</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.007899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4349</th>\n",
       "      <td>401415</td>\n",
       "      <td>quáter</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.006770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334</th>\n",
       "      <td>332839</td>\n",
       "      <td>admitiere</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.006770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>237599</td>\n",
       "      <td>excusación</td>\n",
       "      <td>5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>8</td>\n",
       "      <td>0.006018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4253</th>\n",
       "      <td>217807</td>\n",
       "      <td>encontrare</td>\n",
       "      <td>6</td>\n",
       "      <td>0.03</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>7</td>\n",
       "      <td>0.005266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Orden         Palabra  Frecuencia  Frecuencia_norm  complejidad  freq  \\\n",
       "4340  381324         labrará           2             0.01   100.000000     7   \n",
       "4329  326089         supiere           3             0.01   100.000000     7   \n",
       "4285  253597        apelable           4             0.02    50.000000    11   \n",
       "4336  350809    compareciere           2             0.01   100.000000     4   \n",
       "4303  267522    irrecurrible           4             0.02    50.000000     7   \n",
       "4292  258917  correspondiere           4             0.02    50.000000     7   \n",
       "4349  401415          quáter           2             0.01   100.000000     3   \n",
       "4334  332839       admitiere           2             0.01   100.000000     3   \n",
       "4274  237599      excusación           5             0.03    33.333333     8   \n",
       "4253  217807      encontrare           6             0.03    33.333333     7   \n",
       "\n",
       "      indice_complejidad  \n",
       "4340            0.015797  \n",
       "4329            0.015797  \n",
       "4285            0.012412  \n",
       "4336            0.009027  \n",
       "4303            0.007899  \n",
       "4292            0.007899  \n",
       "4349            0.006770  \n",
       "4334            0.006770  \n",
       "4274            0.006018  \n",
       "4253            0.005266  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpp_f = open('/Users/lucaspecina/Desktop/Data/Planificacion Estrategica/lenguaje-claro/upe-lenguaje_claro/datos/CPP.txt')\n",
    "cpp_raw = cpp_f.read()\n",
    "\n",
    "cpp_tokens = limpieza_textos_simple(cpp_raw, sacar_ere_ese)\n",
    "cpp_tokens, cpp_indice = crear_indice_complejidad(cpp_tokens,corpus,'CPP actual',comunes_sacar)\n",
    "cpp_tokens.sort_values('indice_complejidad',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparacion\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tasa de complejidad de uno sobre el otro es de: \n",
      "1.72 (72.4% mas complejo)\n"
     ]
    }
   ],
   "source": [
    "print(f'La tasa de complejidad de uno sobre el otro es de: \\n{round(cpcc_indice/cpp_indice, 2)} ({round((cpcc_indice-cpp_indice)/cpp_indice*100, 1)}% mas complejo)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
